{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Named Entity Recognition NER +with+NLTK and Spicy .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBwXZA1UOvr0cR1EEfsRKT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhsingh1411/Deep_Learning_Projects/blob/main/NLP/Named_Entity_Recognition_NER_%2Bwith%2BNLTK_and_Spicy_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To understand Name Entity Recognition"
      ],
      "metadata": {
        "id": "d0hTte3-iTY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da"
      ],
      "metadata": {
        "id": "fmAfO3nbiQRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DFLsDpAn5W2h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With the help of NLTK"
      ],
      "metadata": {
        "id": "5lyg-bXa56Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "metadata": {
        "id": "wiJLpHCR5uq7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s5uL2488nAl",
        "outputId": "e94a72f2-9c15-446d-d04a-0756afd56c50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use raw sentence \n",
        "\n",
        "ex = 'European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices'"
      ],
      "metadata": {
        "id": "2JHH7cX17ZKV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(sent):\n",
        "  sent=nltk.word_tokenize(sent)\n",
        "  sent=nltk.pos_tag(sent)\n",
        "  return sent"
      ],
      "metadata": {
        "id": "Etjxrb7N7fdq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent=preprocess(ex)\n",
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sYaA7C08ZV5",
        "outputId": "af75cb81-f993-4e13-beb8-8db2bd15f974"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('European', 'JJ'),\n",
              " ('authorities', 'NNS'),\n",
              " ('fined', 'VBD'),\n",
              " ('Google', 'NNP'),\n",
              " ('a', 'DT'),\n",
              " ('record', 'NN'),\n",
              " ('$', '$'),\n",
              " ('5.1', 'CD'),\n",
              " ('billion', 'CD'),\n",
              " ('on', 'IN'),\n",
              " ('Wednesday', 'NNP'),\n",
              " ('for', 'IN'),\n",
              " ('abusing', 'VBG'),\n",
              " ('its', 'PRP$'),\n",
              " ('power', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('mobile', 'JJ'),\n",
              " ('phone', 'NN'),\n",
              " ('market', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('ordered', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('company', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('alter', 'VB'),\n",
              " ('its', 'PRP$'),\n",
              " ('practices', 'NNS')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(nltk.pos_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK1OZY9q8hnX",
        "outputId": "1f938c16-b163-4541-cb88-6656518d7f1c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function pos_tag in module nltk.tag:\n",
            "\n",
            "pos_tag(tokens, tagset=None, lang='eng')\n",
            "    Use NLTK's currently recommended part of speech tagger to\n",
            "    tag the given list of tokens.\n",
            "    \n",
            "        >>> from nltk.tag import pos_tag\n",
            "        >>> from nltk.tokenize import word_tokenize\n",
            "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"))\n",
            "        [('John', 'NNP'), (\"'s\", 'POS'), ('big', 'JJ'), ('idea', 'NN'), ('is', 'VBZ'),\n",
            "        (\"n't\", 'RB'), ('all', 'PDT'), ('that', 'DT'), ('bad', 'JJ'), ('.', '.')]\n",
            "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"), tagset='universal')\n",
            "        [('John', 'NOUN'), (\"'s\", 'PRT'), ('big', 'ADJ'), ('idea', 'NOUN'), ('is', 'VERB'),\n",
            "        (\"n't\", 'ADV'), ('all', 'DET'), ('that', 'DET'), ('bad', 'ADJ'), ('.', '.')]\n",
            "    \n",
            "    NB. Use `pos_tag_sents()` for efficient tagging of more than one sentence.\n",
            "    \n",
            "    :param tokens: Sequence of tokens to be tagged\n",
            "    :type tokens: list(str)\n",
            "    :param tagset: the tagset to be used, e.g. universal, wsj, brown\n",
            "    :type tagset: str\n",
            "    :param lang: the ISO 639 code of the language, e.g. 'eng' for English, 'rus' for Russian\n",
            "    :type lang: str\n",
            "    :return: The tagged tokens\n",
            "    :rtype: list(tuple(str, str))\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = preprocess(ex)\n",
        "sent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjnGZz-p82tF",
        "outputId": "f5776a83-dc6f-4e6d-cb4e-58f89e217fc4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('European', 'JJ'),\n",
              " ('authorities', 'NNS'),\n",
              " ('fined', 'VBD'),\n",
              " ('Google', 'NNP'),\n",
              " ('a', 'DT'),\n",
              " ('record', 'NN'),\n",
              " ('$', '$'),\n",
              " ('5.1', 'CD'),\n",
              " ('billion', 'CD'),\n",
              " ('on', 'IN'),\n",
              " ('Wednesday', 'NNP'),\n",
              " ('for', 'IN'),\n",
              " ('abusing', 'VBG'),\n",
              " ('its', 'PRP$'),\n",
              " ('power', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('mobile', 'JJ'),\n",
              " ('phone', 'NN'),\n",
              " ('market', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('ordered', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('company', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('alter', 'VB'),\n",
              " ('its', 'PRP$'),\n",
              " ('practices', 'NNS')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our chunk pattern consists of one rule, that a noun phrase, NP, should be formed whenever the chunker finds an optional determiner, DT, followed by any number of adjectives, JJ, and then a noun, NN."
      ],
      "metadata": {
        "id": "SGfMaIiWiPc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = 'NP: {<DT>?<JJ>*<NN>}'"
      ],
      "metadata": {
        "id": "c1r9B6I_WuW9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp=nltk.RegexpParser(pattern)\n",
        "cs=cp.parse(sent)\n",
        "print(cs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKbsGSs4i0g2",
        "outputId": "cf43b8ec-2392-4252-e397-f77cbdf1338d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  European/JJ\n",
            "  authorities/NNS\n",
            "  fined/VBD\n",
            "  Google/NNP\n",
            "  (NP a/DT record/NN)\n",
            "  $/$\n",
            "  5.1/CD\n",
            "  billion/CD\n",
            "  on/IN\n",
            "  Wednesday/NNP\n",
            "  for/IN\n",
            "  abusing/VBG\n",
            "  its/PRP$\n",
            "  (NP power/NN)\n",
            "  in/IN\n",
            "  (NP the/DT mobile/JJ phone/NN)\n",
            "  (NP market/NN)\n",
            "  and/CC\n",
            "  ordered/VBD\n",
            "  (NP the/DT company/NN)\n",
            "  to/TO\n",
            "  alter/VB\n",
            "  its/PRP$\n",
            "  practices/NNS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IOB tags have become the standard way to represent chunk structures in files, and we will also be using this format."
      ],
      "metadata": {
        "id": "d5WRKXRskFLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from pprint import pprint\n",
        "iob_tagged = tree2conlltags(cs)\n",
        "pprint(iob_tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWioSEMvja06",
        "outputId": "a44ccee9-c740-4140-c6af-53a7dadc5994"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('European', 'JJ', 'O'),\n",
            " ('authorities', 'NNS', 'O'),\n",
            " ('fined', 'VBD', 'O'),\n",
            " ('Google', 'NNP', 'O'),\n",
            " ('a', 'DT', 'B-NP'),\n",
            " ('record', 'NN', 'I-NP'),\n",
            " ('$', '$', 'O'),\n",
            " ('5.1', 'CD', 'O'),\n",
            " ('billion', 'CD', 'O'),\n",
            " ('on', 'IN', 'O'),\n",
            " ('Wednesday', 'NNP', 'O'),\n",
            " ('for', 'IN', 'O'),\n",
            " ('abusing', 'VBG', 'O'),\n",
            " ('its', 'PRP$', 'O'),\n",
            " ('power', 'NN', 'B-NP'),\n",
            " ('in', 'IN', 'O'),\n",
            " ('the', 'DT', 'B-NP'),\n",
            " ('mobile', 'JJ', 'I-NP'),\n",
            " ('phone', 'NN', 'I-NP'),\n",
            " ('market', 'NN', 'B-NP'),\n",
            " ('and', 'CC', 'O'),\n",
            " ('ordered', 'VBD', 'O'),\n",
            " ('the', 'DT', 'B-NP'),\n",
            " ('company', 'NN', 'I-NP'),\n",
            " ('to', 'TO', 'O'),\n",
            " ('alter', 'VB', 'O'),\n",
            " ('its', 'PRP$', 'O'),\n",
            " ('practices', 'NNS', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the function nltk.ne_chunk(), we can recognize named entities using a classifier, the classifier adds category labels such as PERSON, ORGANIZATION, and GPE."
      ],
      "metadata": {
        "id": "wdOULHWXkifs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPU4w5fvk25M",
        "outputId": "21691450-cd3c-4167-b516-dcc82d22b289"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHsyksVTk7pk",
        "outputId": "fc54493c-c5e8-415f-bbe1-391a2bcbf901"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ne_chunk\n",
        "ne_tree = ne_chunk(pos_tag(word_tokenize(ex)))\n",
        "print(ne_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHWFd4x4kXyk",
        "outputId": "6b3ef7a8-3eed-488b-e7c7-4e06e2dc8992"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (GPE European/JJ)\n",
            "  authorities/NNS\n",
            "  fined/VBD\n",
            "  (PERSON Google/NNP)\n",
            "  a/DT\n",
            "  record/NN\n",
            "  $/$\n",
            "  5.1/CD\n",
            "  billion/CD\n",
            "  on/IN\n",
            "  Wednesday/NNP\n",
            "  for/IN\n",
            "  abusing/VBG\n",
            "  its/PRP$\n",
            "  power/NN\n",
            "  in/IN\n",
            "  the/DT\n",
            "  mobile/JJ\n",
            "  phone/NN\n",
            "  market/NN\n",
            "  and/CC\n",
            "  ordered/VBD\n",
            "  the/DT\n",
            "  company/NN\n",
            "  to/TO\n",
            "  alter/VB\n",
            "  its/PRP$\n",
            "  practices/NNS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ci0ZcneJkpon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}