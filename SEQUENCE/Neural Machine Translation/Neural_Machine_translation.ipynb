{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Machine_translation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7lmXOv7RfsadEy0Mmm2Tz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhsingh1411/Deep_Learning_Projects/blob/main/SEQUENCE/Neural%20Machine%20Translation/Neural_Machine_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pm3GdXhROHH"
      },
      "source": [
        "import string \n",
        "import re \n",
        "from numpy import array ,argmax ,random,take \n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding,RepeatVector\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "pd.set_option('display.max_colwidth',200)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK1kD6okVI1_"
      },
      "source": [
        "# Reading the files "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtGQXoQ9U1TB"
      },
      "source": [
        "#function to read raw text files \n",
        "\n",
        "def read_text(filename):\n",
        "\n",
        "  #open the file \n",
        "  file = open(filename, mode='rt', encoding='utf-8')\n",
        "\n",
        "  #read all the text \n",
        "  text=file.read()\n",
        "  file.close()\n",
        "\n",
        "  return text "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33UCFidjU1ay"
      },
      "source": [
        "# split a text into sentences\n",
        "\n",
        "def to_lines(text):\n",
        "  sents=text.strip().split('\\n')\n",
        "  sents=[i.split('\\t') for i in sents]\n",
        "\n",
        "  return sents\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ-H3x8IU1eJ"
      },
      "source": [
        "data=read_text('deu.txt')\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = array(deu_eng)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjIu3L7GU1hz",
        "outputId": "761c770d-824b-4902-8943-77d040bcecb4"
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go.', 'Geh.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
              "       ['Hi.', 'Hallo!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "       ['Hi.', 'Grüß Gott!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
              "       ...,\n",
              "       ['May I sit here?', 'Kann ich hier sitzen?',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #61514 (CK) & #804487 (Esperantostern)'],\n",
              "       ['May I use that?', 'Darf ich das benutzen?',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4642215 (CK) & #6645654 (Felixjp)'],\n",
              "       ['May I use this?', 'Darf ich das verwenden?',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #549']],\n",
              "      dtype='<U101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNwVWd1IcqXe"
      },
      "source": [
        "The actual data contains over 150,000 sentence-pairs. However, we will use only the first 50,000 sentence pairs to reduce the training time of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mspcKmZ5U1nA",
        "outputId": "fdf10481-f463-4668-8684-7d7b07b4846f"
      },
      "source": [
        "deu_eng=deu_eng[:50000,:]\n",
        "\n",
        "deu_eng"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go.', 'Geh.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
              "       ['Hi.', 'Hallo!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "       ['Hi.', 'Grüß Gott!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
              "       ...,\n",
              "       ['May I sit here?', 'Kann ich hier sitzen?',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #61514 (CK) & #804487 (Esperantostern)'],\n",
              "       ['May I use that?', 'Darf ich das benutzen?',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #4642215 (CK) & #6645654 (Felixjp)'],\n",
              "       ['May I use this?', 'Darf ich das verwenden?',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #549']],\n",
              "      dtype='<U101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLCYGR2wU1we",
        "outputId": "e03dd599-5b44-43fd-f385-f8f8fe9f0595"
      },
      "source": [
        "deu_eng[0][:2]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Go.', 'Geh.'], dtype='<U101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srm7lL6Lc9Q2"
      },
      "source": [
        "deu_eng_final=[]\n",
        "for i in range(len(deu_eng)):\n",
        "  deu_eng_final.append(deu_eng[i][:2])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGV_ZAsqdK40"
      },
      "source": [
        "deu_eng=array(deu_eng_final)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JerwEbbdjGq",
        "outputId": "ed8d3d8b-0588-4bf8-ed3a-fcb091d9b03c"
      },
      "source": [
        "deu_eng"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go.', 'Geh.'],\n",
              "       ['Hi.', 'Hallo!'],\n",
              "       ['Hi.', 'Grüß Gott!'],\n",
              "       ...,\n",
              "       ['May I sit here?', 'Kann ich hier sitzen?'],\n",
              "       ['May I use that?', 'Darf ich das benutzen?'],\n",
              "       ['May I use this?', 'Darf ich das verwenden?']], dtype='<U101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtIhecxedsUq",
        "outputId": "887b4760-7170-4cc8-c708-2ab5482ff5fd"
      },
      "source": [
        "# Remove punctuation\n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
        "\n",
        "deu_eng"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go', 'Geh'],\n",
              "       ['Hi', 'Hallo'],\n",
              "       ['Hi', 'Grüß Gott'],\n",
              "       ...,\n",
              "       ['May I sit here', 'Kann ich hier sitzen'],\n",
              "       ['May I use that', 'Darf ich das benutzen'],\n",
              "       ['May I use this', 'Darf ich das verwenden']], dtype='<U101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cujCK8Gbd5fR",
        "outputId": "f75e4069-5ca9-4dc5-ef17-35169848bd91"
      },
      "source": [
        "# convert text to lowercase\n",
        "for i in range(len(deu_eng)):\n",
        "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
        "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
        "\n",
        "deu_eng"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['go', 'geh'],\n",
              "       ['hi', 'hallo'],\n",
              "       ['hi', 'grüß gott'],\n",
              "       ...,\n",
              "       ['may i sit here', 'kann ich hier sitzen'],\n",
              "       ['may i use that', 'darf ich das benutzen'],\n",
              "       ['may i use this', 'darf ich das verwenden']], dtype='<U101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfyeOxaXeavw"
      },
      "source": [
        "**Text to sequence conversion **\n",
        "\n",
        "A Seq2Seq model requires that we convert both the input and the output sentences into integer sequences of fixed length.\n",
        "\n",
        "But before we do that, let’s visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and German, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "mo3yrNOPd9xZ",
        "outputId": "56f09554-08eb-425d-e13f-559805eaf029"
      },
      "source": [
        "#empty_list \n",
        "eng_l=[]\n",
        "deu_l=[]\n",
        "\n",
        "#populate the list with sentence length \n",
        "for i in deu_eng[:,0]:\n",
        "  eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "  deu_l.append(len(i.split()))\n",
        "\n",
        "length_df=pd.DataFrame({'eng':eng_l,'deu':deu_l})\n",
        "\n",
        "length_df.hist(bins=30)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "wZFHXbKinVrQ",
        "outputId": "75ca119b-ca2d-4352-d9c7-1e9656a4b465"
      },
      "source": [
        "length_df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>deu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   eng  deu\n",
              "0    1    1\n",
              "1    1    1\n",
              "2    1    2\n",
              "3    1    1\n",
              "4    1    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP93eyVdnnLR"
      },
      "source": [
        "Note that we will prepare tokenizers for both the German and English sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRBv8gqXnhGs"
      },
      "source": [
        "def tokenization(lines):\n",
        "  tokenizer=Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "\n",
        "  return tokenizer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyqA20HNn5tD",
        "outputId": "82fadd91-6063-4257-fed9-cfffc2ae9dcd"
      },
      "source": [
        "#prepare english tokenizer \n",
        "eng_tokenizer=tokenization(deu_eng[:,0])\n",
        "\n",
        "eng_vocab_size=len(eng_tokenizer.word_index)+1\n",
        "\n",
        "eng_length=8\n",
        "\n",
        "print('English vocab size',eng_vocab_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English vocab size 2086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ht3rNiGn6Od",
        "outputId": "0e42acfd-b1e1-4a12-d19c-403e18f66702"
      },
      "source": [
        "#prepare deuth tokenizer \n",
        "deu_tokenizer=tokenization(deu_eng[:,1])\n",
        "\n",
        "deu_vocab_size=len(deu_tokenizer.word_index)+1\n",
        "\n",
        "deu_length=8\n",
        "\n",
        "print('deuth vocab size',deu_vocab_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deuth vocab size 3416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndDUhdzCn6Ul",
        "outputId": "da3e46f0-2c86-4d97-bf22-c4443bf8417d"
      },
      "source": [
        "eng_tokenizer"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7ff70ff59e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX1E2BOvn6Xn"
      },
      "source": [
        "def encode_sequences(tokenizer,length,lines):\n",
        "  seq=tokenizer.texts_to_sequences(lines)\n",
        "  seq=pad_sequences(seq,maxlen=length,padding='post')\n",
        "\n",
        "  return seq "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgtMoHVIqcOe"
      },
      "source": [
        "Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLkTwosbn6bJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into train and test set\n",
        "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtFPjdFQqaog",
        "outputId": "98b7ec34-401a-4b2b-a955-8a2f76ffa7e8"
      },
      "source": [
        "test"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['she was naive', 'sie war leichtgläubig'],\n",
              "       ['he has no fear', 'er fürchtet sich nicht'],\n",
              "       ['drop the gun', 'lass die waffe fallen'],\n",
              "       ...,\n",
              "       ['tom is stingy', 'tom ist geizig'],\n",
              "       ['who found tom', 'wer hat tom gefunden'],\n",
              "       ['write me', 'schreibt mir']], dtype='<U101')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7oX9hDBqaxU"
      },
      "source": [
        "#prepare training and testing data\n",
        "\n",
        "# prepare training data\n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "\n",
        "# prepare validation data\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMxCkvoeqa0i",
        "outputId": "ede52e37-6577-4314-8f28-e4aa4819e68f"
      },
      "source": [
        "print(trainX.shape,trainY.shape,testX.shape,testY.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7232, 8) (7232, 8) (1808, 8) (1808, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnbpGaYgqa3w",
        "outputId": "98738cb8-e6f9-447a-f5f8-da69cbfddbd7"
      },
      "source": [
        "trainX"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   2,  514,  100, ...,    0,    0,    0],\n",
              "       [ 963,   41,    0, ...,    0,    0,    0],\n",
              "       [ 217,   67,   15, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  12, 3027,    0, ...,    0,    0,    0],\n",
              "       [   7,    1,  825, ...,    0,    0,    0],\n",
              "       [   1,  721,    6, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT8WabLtsFSz"
      },
      "source": [
        "Model Architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLmCxYxuqa6G"
      },
      "source": [
        "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units):\n",
        "      model = Sequential()\n",
        "      model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "      model.add(LSTM(units))\n",
        "      model.add(RepeatVector(out_timesteps))\n",
        "      model.add(LSTM(units, return_sequences=True))\n",
        "      model.add(Dense(out_vocab, activation='softmax'))\n",
        "      return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s63cmBghqa9p",
        "outputId": "a2066e9a-56a2-4165-f2af-92c9fe2e509b"
      },
      "source": [
        "#model.compilation \n",
        "model=define_model(deu_vocab_size,eng_vocab_size,deu_length,eng_length,512)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 8, 512)            1748992   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "repeat_vector (RepeatVector) (None, 8, 512)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 8, 512)            2099200   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 8, 2086)           1070118   \n",
            "=================================================================\n",
            "Total params: 7,017,510\n",
            "Trainable params: 7,017,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_yImRLzuBbL",
        "outputId": "388f9a68-25f8-4e5c-eb62-aba7edb93508"
      },
      "source": [
        "print(deu_vocab_size,eng_vocab_size,deu_length,eng_length)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3416 2086 8 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWPlHGX4uE9I"
      },
      "source": [
        "rms=optimizers.RMSprop(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=rms,loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCKQ5iKRuXWf",
        "outputId": "f50a049d-1e07-4be5-b8bd-4fe826f487a2"
      },
      "source": [
        "filename = 'model.h1.24_jan_19'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\n",
        "                    epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \n",
        "                    verbose=1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "12/12 [==============================] - 37s 182ms/step - loss: 5.3217 - val_loss: 2.5929\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.59290, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/30\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 2.4256 - val_loss: 2.5377\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.59290 to 2.53773, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/30\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 2.2392 - val_loss: 2.2702\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.53773 to 2.27017, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/30\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 2.0706 - val_loss: 2.1084\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.27017 to 2.10840, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/30\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 1.9889 - val_loss: 2.1003\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.10840 to 2.10031, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/30\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1.9492 - val_loss: 2.0835\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.10031 to 2.08354, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/30\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1.9277 - val_loss: 2.0348\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.08354 to 2.03480, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/30\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 1.8916 - val_loss: 2.0185\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.03480 to 2.01852, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/30\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 1.8578 - val_loss: 1.9946\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.01852 to 1.99459, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/30\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 1.8048 - val_loss: 1.9592\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.99459 to 1.95915, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/30\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 1.7692 - val_loss: 1.9618\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.95915\n",
            "Epoch 12/30\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 1.7174 - val_loss: 1.8897\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.95915 to 1.88973, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/30\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 1.6752 - val_loss: 1.8838\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.88973 to 1.88378, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/30\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 1.6153 - val_loss: 1.8768\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.88378 to 1.87683, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/30\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1.5772 - val_loss: 1.8462\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.87683 to 1.84620, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/30\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1.5177 - val_loss: 1.8482\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.84620\n",
            "Epoch 17/30\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 1.5129 - val_loss: 1.8070\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.84620 to 1.80697, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18/30\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1.4508 - val_loss: 1.7849\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.80697 to 1.78492, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19/30\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 1.4048 - val_loss: 1.7815\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.78492 to 1.78146, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20/30\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 1.3707 - val_loss: 1.7569\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.78146 to 1.75691, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/30\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 1.3266 - val_loss: 1.7866\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.75691\n",
            "Epoch 22/30\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 1.2863 - val_loss: 1.7680\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.75691\n",
            "Epoch 23/30\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 1.2697 - val_loss: 1.7385\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.75691 to 1.73847, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24/30\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1.2221 - val_loss: 1.6926\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.73847 to 1.69258, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25/30\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 1.1707 - val_loss: 1.7718\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.69258\n",
            "Epoch 26/30\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1.1684 - val_loss: 1.6987\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.69258\n",
            "Epoch 27/30\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 1.1176 - val_loss: 1.6899\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.69258 to 1.68995, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 28/30\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 1.0839 - val_loss: 1.7054\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.68995\n",
            "Epoch 29/30\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 1.0606 - val_loss: 1.6444\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.68995 to 1.64445, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 30/30\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 1.0319 - val_loss: 1.6411\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.64445 to 1.64108, saving model to model.h1.24_jan_19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.24_jan_19/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "11LikLvouxPG",
        "outputId": "c73b639c-7c00-4e2b-8a6a-74839492e11e"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpS4-CgQvzED",
        "outputId": "e1c8b372-097b-4759-9917-5b68f409605b"
      },
      "source": [
        "model = load_model('model.h1.24_jan_19')\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLv9iYEGwETw"
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "      for word, index in tokenizer.word_index.items():\n",
        "          if index == n:\n",
        "              return word\n",
        "      return None"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ7MIx67wEcN"
      },
      "source": [
        "preds_text = []\n",
        "for i in preds:\n",
        "       temp = []\n",
        "       for j in range(len(i)):\n",
        "            t = get_word(i[j], eng_tokenizer)\n",
        "            if j > 0:\n",
        "                if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                     temp.append('')\n",
        "                else:\n",
        "                     temp.append(t)\n",
        "            else:\n",
        "                   if(t == None):\n",
        "                          temp.append('')\n",
        "                   else:\n",
        "                          temp.append(t) \n",
        "\n",
        "       preds_text.append(' '.join(temp))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98QAqBDcwEgc"
      },
      "source": [
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "Ecs1LJajwEkC",
        "outputId": "b79751e8-8e7a-4188-8fc4-05efca2ed748"
      },
      "source": [
        "# print 15 rows randomly\n",
        "pred_df.sample(15)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1042</th>\n",
              "      <td>were close</td>\n",
              "      <td>were won</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>go home</td>\n",
              "      <td>go back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>i fainted</td>\n",
              "      <td>i said to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1278</th>\n",
              "      <td>ignore them</td>\n",
              "      <td>come them</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1665</th>\n",
              "      <td>i need a smoke</td>\n",
              "      <td>i want a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>go away</td>\n",
              "      <td>go away</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1723</th>\n",
              "      <td>whos paying</td>\n",
              "      <td>who away</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1263</th>\n",
              "      <td>she needs you</td>\n",
              "      <td>they found it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>tom is joking</td>\n",
              "      <td>tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1503</th>\n",
              "      <td>are you tom</td>\n",
              "      <td>youre tom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>be yourself</td>\n",
              "      <td>be caution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>its happened</td>\n",
              "      <td>it works</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1569</th>\n",
              "      <td>go away</td>\n",
              "      <td>go away</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>have courage</td>\n",
              "      <td>be ruthless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>how romantic</td>\n",
              "      <td>how me</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              actual           predicted\n",
              "1042      were close      were won      \n",
              "1796         go home       go back      \n",
              "477        i fainted      i said to     \n",
              "1278     ignore them     come them      \n",
              "1665  i need a smoke       i want a     \n",
              "736          go away       go away      \n",
              "1723     whos paying      who away      \n",
              "1263   she needs you  they found it     \n",
              "392    tom is joking          tom       \n",
              "1503     are you tom     youre tom      \n",
              "1716     be yourself    be caution      \n",
              "606     its happened      it works      \n",
              "1569         go away       go away      \n",
              "942     have courage   be ruthless      \n",
              "517     how romantic        how me      "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}